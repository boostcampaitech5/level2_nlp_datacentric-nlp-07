{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install 'cleanlab[datalab]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DsadmWY3yLP3",
    "outputId": "726cee26-b416-4f3c-ea85-e9bd82defeeb"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44zHtw3U1cJr",
    "outputId": "c9587f2f-23c5-4f85-e213-ca365ebbd6b8"
   },
   "outputs": [],
   "source": [
    "# !pip install kobert-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dw6wwgPtxrhm",
    "outputId": "3a507c3a-c162-4cb2-f79f-c86bbcb1c821"
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# !pip install cleanlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uckUgGucx7Qo"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "import re \n",
    "import string \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import AutoModel\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cleanlab import Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "int2label = [\"ITSci\", \"Economic\", \"Society\",\"Life\", \"World\", \"Sports\", \"Politics\"]\n",
    "# int2label = [\"IT과학\", \"경제\", \"사회\", \"생활문화\", \"세계\", \"스포츠\", \"정치\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "uKtmPLUUzaAM",
    "outputId": "1ee5b3c7-4a4f-45c1-b43f-4b30c3415f80",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "data = data.drop(data[data[\"text\"].isnull() == True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_embedding ([CLS] sentence embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_texts, labels = data[\"text\"].values, data[\"target\"].values\n",
    "num_classes = len(set(labels))\n",
    "print(f\"This dataset has {num_classes} classes.\")\n",
    "print(f\"Classes: {set(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "transformer = get_kobert_model()\n",
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=4096# 2048\n",
    "transformer.eval()\n",
    "text_embeddings = []\n",
    "for batch in tqdm(DataLoader(raw_texts, batch_size=BATCH_SIZE)):\n",
    "    with torch.no_grad():\n",
    "        input = tokenizer(batch, padding=True, return_tensors=\"pt\").to(DEVICE)\n",
    "        output = transformer(**input).pooler_output\n",
    "    text_embeddings.append(output)\n",
    "    \n",
    "total = torch.cat(text_embeddings)\n",
    "text_embeddings = total.cpu().detach().numpy()\n",
    "print(text_embeddings.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier, NeuralNet\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = 'monologg/kobert'\n",
    "# tokenizer = KoBertTokenizer.from_pretrained(model_name) # transformer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7).to(DEVICE)\n",
    "model_skorch = NeuralNet(model, criterion=nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        input_texts = data['text']\n",
    "        targets = data['target']\n",
    "        self.inputs = []; self.labels = []\n",
    "        for text, label in zip(input_texts, targets):\n",
    "            tokenized_input = tokenizer(text, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'].squeeze(0),  \n",
    "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx].squeeze(0)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = BERTDataset(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_probs = cross_val_predict(\n",
    "    model_skorch, dataset, labels, \n",
    "    cv=5, method=\"predict_proba\", verbose=1\n",
    ")\n",
    "predicted_labels = pred_probs.argmax(axis=1)\n",
    "acc = accuracy_score(labels, predicted_labels)\n",
    "print(f\"Cross-validated estimate of accuracy on held-out data: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)\n",
    "m =  nn.Softmax(dim=1)\n",
    "print(a)\n",
    "m(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_labels = 7\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, 7)\n",
    "        self.softmax = nn.Softmax(dim=1) # acc = 0.577643015084178\n",
    "        # self.softmax = nn.LogSoftmax(dim=1) # acc = 0.04608446263984062\n",
    "\n",
    "        # self.post_init()\n",
    "\n",
    "    def forward(self, X):\n",
    "        tmp = self.dropout(X)\n",
    "        logits = self.classifier(tmp)\n",
    "        logits = self.softmax(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_skorch = NeuralNetClassifier(ClassifierModule, criterion=nn.CrossEntropyLoss) # acc =  0.3926264859776255\n",
    "model_skorch = NeuralNetClassifier(ClassifierModule, max_epochs=20) # cross entropy = 0.3926264859776255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_probs = cross_val_predict(\n",
    "    model_skorch, text_embeddings, labels, \n",
    "    cv=5, method=\"predict_proba\", verbose=1\n",
    ")\n",
    "predicted_labels = pred_probs.argmax(axis=1)\n",
    "acc = accuracy_score(labels, predicted_labels)\n",
    "print(f\"Cross-validated estimate of accuracy on held-out data: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_probs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LogisticRegression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=400, verbose=1)\n",
    "pred_probs = cross_val_predict(model, text_embeddings, labels, method=\"predict_proba\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted_labels = pred_probs.argmax(axis=1)\n",
    "acc = accuracy_score(labels, predicted_labels)\n",
    "print(f\"Cross-validated estimate of accuracy on held-out data: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find label issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {\"texts\": raw_texts, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab = Datalab(data_dict, label_name=\"labels\")\n",
    "lab.find_issues(pred_probs=pred_probs, features=text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(\n",
    "{\n",
    "    \"text\": raw_texts,\n",
    "    \"target\": labels,\n",
    "    \"suggested\": label_issues[\"predicted_label\"],\n",
    "    \"given_label\": [int2label[x] for x in labels],\n",
    "    \"suggested_label\": label_issues[\"predicted_label\"].apply(lambda x: int2label[x]),\n",
    "    \"label_score\": label_issues[\"label_score\"],\n",
    "    \"error\": label_issues[\"is_label_issue\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.to_csv(\"cleanlab_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 에러, 에러 아닌 개수\n",
    "print(\"error\", len(res_df[res_df[\"target\"] != res_df[\"suggested\"]]))\n",
    "print(\"right\", len(res_df[res_df[\"target\"] == res_df[\"suggested\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 에러만 따로 빼서 보기\n",
    "error_df = res_df[res_df[\"given_label\"] != res_df[\"suggested_label\"]].sort_values(\"label_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"< 0.01\",len(error_df[error_df[\"label_score\"]  < 0.01]))\n",
    "print(\"< 0.02\", len(error_df[error_df[\"label_score\"]  < 0.02]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 수정할 threshold 설정\n",
    "to_change = error_df[error_df[\"label_score\"]  < 0.02]\n",
    "to_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_change.groupby(\"suggested_label\")[\"text\"].count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_change.groupby(\"given_label\")[\"text\"].count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_change.groupby([\"given_label\", \"suggested_label\"])[\"text\"].count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 라벨 에러 삭제\n",
    "new_train = data.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 라벨 에러 예측된 값으로 수정\n",
    "new_train = train_df.copy()\n",
    "for i in index:\n",
    "    new_train.loc[i, \"target\"] = to_change.loc[i, \"suggested\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train.to_csv(\"new_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "train_data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tqdm(data.itertuples()):\n",
    "    tokens = tokenizer(i.text)\n",
    "    max_len = max(max_len, len(tokens.input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(test_data.itertuples()):\n",
    "    tokens = tokenizer(i.text)\n",
    "    max_len = max(max_len, len(tokens.input_ids))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(train_data.itertuples()):\n",
    "    tokens = tokenizer(i.text)\n",
    "    max_len = max(max_len, len(tokens.input_ids))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data[\"len\"] = train_data[\"text\"].apply(lambda x: len(x))\n",
    "sen = train_data[[\"text\", \"len\"]].sort_values(\"len\")\n",
    "sen[sen.len < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data[\"len\"] = test_data[\"text\"].apply(lambda x: len(x))\n",
    "sen = test_data[[\"text\", \"len\"]].sort_values(\"len\")\n",
    "sen[sen.len < 10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
